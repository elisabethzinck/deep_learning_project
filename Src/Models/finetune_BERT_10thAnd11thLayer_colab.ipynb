{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune_BERT_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRU4K5zWVemp"
      },
      "source": [
        "This is the version of finetuning which tunes the 10th and 11th layer\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6qtNFQyCIsv"
      },
      "source": [
        "# Start cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soayi6Ax2IvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abd75db-e07f-480d-e41b-2344533205ea"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhfaJA87lU-"
      },
      "source": [
        "# Loading requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBaXjuKD7ohz",
        "outputId": "b00b5f79-a4eb-47b4-a998-06172f9d35a8"
      },
      "source": [
        "! pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyBsg1w_7qyN",
        "outputId": "2b97adcb-2c09-4f07-f5f7-4ea438d04902"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROqy8ROq8zf5"
      },
      "source": [
        "# Import things to get data to work\n",
        "from datasets import load_from_disk\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vOZHVO25zRn"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6q90R05g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd47386-055a-4075-9f45-1bd9a505062c"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvO9AFoF9KGo"
      },
      "source": [
        "sys.path.append(os.path.join('/content/drive/My Drive/deep_learning_project'))\n",
        "train_path = 'drive/My Drive/deep_learning_project/train_small'\n",
        "val_path = 'drive/My Drive/deep_learning_project/validation_small'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww9b_fsX5nXx"
      },
      "source": [
        "train_data = load_from_disk(train_path)\n",
        "validation_data = load_from_disk(val_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2EhY8a58yaq",
        "outputId": "0d3890e6-35c6-43bf-ed61-7e734871b4b5"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'answer': 'york', 'paragraph': ['[P] judi dench', 'born in dorset and later moved to dublin where he was raised he met dench s mother while he was studying medicine at trinity college dublin dench attended the mount school a quaker independent secondary school in york and became a quaker her brothers one of whom was actor jeffery dench were born in tyldesley lancashire her niece emma dench is a roman historian and professor previously at birkbeck university of london and currently at harvard university career in britain dench has developed a reputation as one of the greatest actresses of the post war period primarily through her work in theatre which has been her forte throughout her career she has more than once been named number one in polls for britain s best actor early years'], 'question': ['[Q]', 'Where in England was Dame Judi Dench born?'], 'question_id': 'tc_3'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4JOtDMX9tyq"
      },
      "source": [
        "# Preparing data for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI0jM5Xl9_kn"
      },
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel, AdamW"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm_gD863_UBR"
      },
      "source": [
        "def get_loss(sim):\n",
        "    nll = -(torch.diagonal(sim) - torch.logsumexp(sim, dim = 1))\n",
        "    return sum(nll)# return negative loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJOd_09093vQ"
      },
      "source": [
        "# Define data parameters\n",
        "batch_size = 16\n",
        "\n",
        "# Train\n",
        "n_sample_train = 1024 #ceil(len(train_data)*0.02) \n",
        "n_batches_train = ceil(n_sample_train/batch_size)\n",
        "# Validation\n",
        "n_sample_validation = 128 #ceil(len(validation_data)*0.05)\n",
        "n_batches_validation = ceil(n_sample_validation/batch_size)\n",
        "\n",
        "\n",
        "# Define model parameters\n",
        "lr = 5e-5\n",
        "n_epochs = 4\n",
        "\n",
        "# Define printing parameters\n",
        "n_batch_print = 5 # Prints every (n_batch_print) during training"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYfy9sQoKS7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2760fe-3dae-49bb-97ca-0c59e6b396f2"
      },
      "source": [
        "print(f\"Validation Samples: {n_sample_validation}\")\n",
        "print(f\"Training Samples: {n_sample_train}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Samples: 128\n",
            "Training Samples: 1024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAJeVShU-JLO",
        "outputId": "a819e3bc-6332-4749-da63-81567091b7f0"
      },
      "source": [
        "# NB CHANGE THIS CELL WHEN THE DATA IS READY###############\n",
        "# Subset data\n",
        "train_data = train_data.select(range(n_sample_train))\n",
        "validation_data = validation_data.select(range(n_sample_validation))\n",
        "\n",
        "# Tokenize data\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', padding = True)\n",
        "train_data = train_data.map(lambda example: {\n",
        "    'Q_input_ids': tokenizer(example['question'], padding = 'max_length')['input_ids'],\n",
        "    'Q_attention_mask': tokenizer(example['question'], padding = 'max_length')['attention_mask'],\n",
        "    'Q_token_type_ids': tokenizer(example['question'], padding = 'max_length')['token_type_ids'],\n",
        "    'P_input_ids': tokenizer(example['paragraph'], padding = 'max_length')['input_ids'],\n",
        "    'P_attention_mask': tokenizer(example['paragraph'], padding = 'max_length')['attention_mask'],\n",
        "    'P_token_type_ids': tokenizer(example['paragraph'], padding = 'max_length')['token_type_ids']},\n",
        "    batched = True, batch_size= batch_size)\n",
        "\n",
        "validation_data = validation_data.map(lambda example: {\n",
        "    'Q_input_ids': tokenizer(example['question'], padding = 'max_length')['input_ids'],\n",
        "    'Q_attention_mask': tokenizer(example['question'], padding = 'max_length')['attention_mask'],\n",
        "    'Q_token_type_ids': tokenizer(example['question'], padding = 'max_length')['token_type_ids'],\n",
        "    'P_input_ids': tokenizer(example['paragraph'], padding = 'max_length')['input_ids'],\n",
        "    'P_attention_mask': tokenizer(example['paragraph'], padding = 'max_length')['attention_mask'],\n",
        "    'P_token_type_ids': tokenizer(example['paragraph'], padding = 'max_length')['token_type_ids']},\n",
        "    batched = True, batch_size= batch_size)\n",
        "\n",
        "#%% Change to pytorch format. \n",
        "train_data.set_format(type = 'torch', \n",
        "                        columns = ['Q_input_ids', 'Q_attention_mask', 'Q_token_type_ids',\n",
        "                                   'P_input_ids', 'P_attention_mask', 'P_token_type_ids'])\n",
        "\n",
        "validation_data.set_format(type = 'torch', \n",
        "                        columns = ['Q_input_ids', 'Q_attention_mask', 'Q_token_type_ids',\n",
        "                                   'P_input_ids', 'P_attention_mask', 'P_token_type_ids'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at drive/My Drive/deep_learning_project/train_small/cache-3db223f62f19b72f.arrow\n",
            "Loading cached processed dataset at drive/My Drive/deep_learning_project/validation_small/cache-746246346f88e487.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlh6z4VKLtN"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmRsdg1d-xrw"
      },
      "source": [
        "# Get pretrained model\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Freezing all layers except the last ones\n",
        "l11 = [\"encoder.layer.11\" in name[0] for name in model.named_parameters()]\n",
        "l10 = [\"encoder.layer.10\" in name[0] for name in model.named_parameters()]\n",
        "l9 = [\"encoder.layer.9\" in name[0] for name in model.named_parameters()]\n",
        "layers_to_opt = list(map(any, zip(*[l10, l11])))\n",
        "params = [name[0] for name in model.named_parameters()]\n",
        "param_to_be_optimized = [name for (layer, name) in zip(layers_to_opt, params) if layer]\n",
        "for name, param in model.named_parameters():\n",
        "  if not name in param_to_be_optimized:\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Move model to cuda to train there\n",
        "model.to(device)\n",
        "\n",
        "optim = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr = lr) # filter object works as a generator "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRAU6y9JMa__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55884c46-bff0-460a-d70c-6c1424796ed9"
      },
      "source": [
        "# Print the weights that are being updated\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder.layer.10.attention.self.query.weight\n",
            "encoder.layer.10.attention.self.query.bias\n",
            "encoder.layer.10.attention.self.key.weight\n",
            "encoder.layer.10.attention.self.key.bias\n",
            "encoder.layer.10.attention.self.value.weight\n",
            "encoder.layer.10.attention.self.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.weight\n",
            "encoder.layer.10.attention.output.LayerNorm.bias\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.weight\n",
            "encoder.layer.10.output.LayerNorm.bias\n",
            "encoder.layer.11.attention.self.query.weight\n",
            "encoder.layer.11.attention.self.query.bias\n",
            "encoder.layer.11.attention.self.key.weight\n",
            "encoder.layer.11.attention.self.key.bias\n",
            "encoder.layer.11.attention.self.value.weight\n",
            "encoder.layer.11.attention.self.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.weight\n",
            "encoder.layer.11.attention.output.LayerNorm.bias\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.weight\n",
            "encoder.layer.11.output.LayerNorm.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPZogvfK9vF2",
        "outputId": "b13a71fe-e384-406f-fb41-b9c1a1b7db84"
      },
      "source": [
        "# The big loop :D \n",
        "epoch_train_loss = [None]*n_batches_train\n",
        "epoch_validation_loss = [None]*n_batches_validation\n",
        "train_loss = [None]*n_epochs\n",
        "validation_loss = [None]*n_epochs\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    print(f'### EPOCH: {epoch+1}/{n_epochs} ###')\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    trainloader = iter(trainloader)\n",
        "    validationloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size)\n",
        "    validationloader = iter(validationloader)\n",
        "    \n",
        "    # TRAINING MODEL\n",
        "    model.train()\n",
        "    for i, batch in enumerate(trainloader):\n",
        "        if i % n_batch_print == 0:\n",
        "          print(f'batch {i+1}/{len(trainloader)}')\n",
        "        \n",
        "        model.zero_grad()\n",
        "\n",
        "        # Make forward pass for paragraphs\n",
        "        input_ids = batch['P_input_ids'].to(device)\n",
        "        attention_mask = batch['P_attention_mask'].to(device)\n",
        "        token_type_ids = batch['P_token_type_ids'].to(device)\n",
        "        P_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)#[0][:, 0, :]\n",
        "        # concatenating hidden layers\n",
        "        P_cat = torch.cat(tuple([P_encoded_layers.hidden_states[i] for i in [-2, -1]]), dim=-1)  \n",
        "        P_cat = P_cat[:, 0, :]\n",
        "        #pooled_output = nn.Dropout(pooled_output)\n",
        "        \n",
        "        # Make forward pass for questions\n",
        "        input_ids = batch['Q_input_ids'].to(device)\n",
        "        attention_mask = batch['Q_attention_mask'].to(device)\n",
        "        token_type_ids = batch['Q_token_type_ids'].to(device)\n",
        "        Q_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)#[0][:, 0, :]\n",
        "        # concatenating hidden layers\n",
        "        Q_cat = torch.cat(tuple([Q_encoded_layers.hidden_states[i] for i in [-2, -1]]), dim=-1)  \n",
        "        Q_cat = Q_cat[:, 0, :]\n",
        "\n",
        "        # Calculate similarity matrix\n",
        "        sim_matrix = torch.matmul(Q_cat, P_cat.T)\n",
        "        \n",
        "        # Get loss\n",
        "        loss = get_loss(sim_matrix)\n",
        "        #loss.requires_grad = True\n",
        "\n",
        "        # Update weights\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        # Save loss\n",
        "        epoch_train_loss[i] = loss.item()\n",
        "\n",
        "    # VALIDATING MODEL\n",
        "    model.eval()\n",
        "    for i, batch in enumerate(validationloader):\n",
        "        \n",
        "        # (get extra observation in training set)\n",
        "\n",
        "        # Make forward pass for paragraphs\n",
        "        input_ids = batch['P_input_ids'].to(device)\n",
        "        attention_mask = batch['P_attention_mask'].to(device)\n",
        "        token_type_ids = batch['P_token_type_ids'].to(device)\n",
        "        P_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)#[0][:, 0, :]\n",
        "        \n",
        "        # concatenating hidden layers\n",
        "        P_cat = torch.cat(tuple([P_encoded_layers.hidden_states[i] for i in [-2, -1]]), dim=-1)  \n",
        "        P_cat = P_cat[:, 0, :]\n",
        "\n",
        "        # Make forward pass for questions\n",
        "        input_ids = batch['Q_input_ids'].to(device)\n",
        "        attention_mask = batch['Q_attention_mask'].to(device)\n",
        "        token_type_ids = batch['Q_token_type_ids'].to(device)\n",
        "        Q_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)#[0][:, 0, :]\n",
        "        # concatenating hidden layers\n",
        "        Q_cat = torch.cat(tuple([Q_encoded_layers.hidden_states[i] for i in [-2, -1]]), dim=-1)  \n",
        "        Q_cat = Q_cat[:, 0, :]\n",
        "\n",
        "        # Calculate similarity matrix\n",
        "        sim_matrix = torch.matmul(Q_cat, P_cat.T)\n",
        "\n",
        "        # Get loss\n",
        "        loss = get_loss(sim_matrix)\n",
        "        epoch_validation_loss[i] = loss.item()\n",
        "        \n",
        "    \n",
        "    train_loss[epoch] = sum(epoch_train_loss)/len(epoch_train_loss)\n",
        "    validation_loss[epoch] = sum(epoch_validation_loss)/len(epoch_validation_loss)\n",
        "    \n",
        "    print(f'train loss: {train_loss[epoch]:.2f}')\n",
        "    print(f'validation loss: {validation_loss[epoch]:.2f}')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### EPOCH: 1/4 ###\n",
            "batch 1/64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py:850: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.tensor(x, **format_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch 6/64\n",
            "batch 11/64\n",
            "batch 16/64\n",
            "batch 21/64\n",
            "batch 26/64\n",
            "batch 31/64\n",
            "batch 36/64\n",
            "batch 41/64\n",
            "batch 46/64\n",
            "batch 51/64\n",
            "batch 56/64\n",
            "batch 61/64\n",
            "train loss: 267.29\n",
            "validation loss: 36.67\n",
            "### EPOCH: 2/4 ###\n",
            "batch 1/64\n",
            "batch 6/64\n",
            "batch 11/64\n",
            "batch 16/64\n",
            "batch 21/64\n",
            "batch 26/64\n",
            "batch 31/64\n",
            "batch 36/64\n",
            "batch 41/64\n",
            "batch 46/64\n",
            "batch 51/64\n",
            "batch 56/64\n",
            "batch 61/64\n",
            "train loss: 66.04\n",
            "validation loss: 17.80\n",
            "### EPOCH: 3/4 ###\n",
            "batch 1/64\n",
            "batch 6/64\n",
            "batch 11/64\n",
            "batch 16/64\n",
            "batch 21/64\n",
            "batch 26/64\n",
            "batch 31/64\n",
            "batch 36/64\n",
            "batch 41/64\n",
            "batch 46/64\n",
            "batch 51/64\n",
            "batch 56/64\n",
            "batch 61/64\n",
            "train loss: 34.24\n",
            "validation loss: 10.32\n",
            "### EPOCH: 4/4 ###\n",
            "batch 1/64\n",
            "batch 6/64\n",
            "batch 11/64\n",
            "batch 16/64\n",
            "batch 21/64\n",
            "batch 26/64\n",
            "batch 31/64\n",
            "batch 36/64\n",
            "batch 41/64\n",
            "batch 46/64\n",
            "batch 51/64\n",
            "batch 56/64\n",
            "batch 61/64\n",
            "train loss: 16.44\n",
            "validation loss: 9.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnB-hrrIOe-S"
      },
      "source": [
        "#model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3i1oLjBWL9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1726d2f-7ef5-466f-fab7-098e535cf082"
      },
      "source": [
        "print(validation_loss)\n",
        "print(train_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36.66849708557129, 17.795429229736328, 10.321479797363281, 9.685201644897461]\n",
            "[267.29035329818726, 66.03806138038635, 34.24101364612579, 16.44493079185486]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM095XYxWEpe"
      },
      "source": [
        "#%% Saving model\n",
        "#model_path = 'drive/My Drive/BERT_Model/8_percent/'\n",
        "#model.save_pretrained(model_path)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOaGE4RAaaA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9c5fdb43-472f-4e0f-bcdc-a23471d7b446"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(range(1, n_epochs+1), train_loss, label = 'Train loss')\n",
        "plt.plot(range(1, n_epochs+1), validation_loss, label = 'Validation loss')\n",
        "plt.title('Finetuning BERT Base Model')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "#fig.savefig(\"drive/My Drive/deep_learning_project/figures/BERTbaseFinetuning_pooled_output.pdf\", bbox_inches='tight')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcJgm4bKCQ9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a55a1dc-3935-4387-c9dc-7a4977cb42e7"
      },
      "source": [
        "validation_loss\n",
        "train_loss"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[267.29035329818726, 66.03806138038635, 34.24101364612579, 16.44493079185486]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt6-DU072GYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a65041-c1dc-472e-b9d2-306907e43814"
      },
      "source": [
        "print(validation_loss)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36.66849708557129, 17.795429229736328, 10.321479797363281, 9.685201644897461]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC4ui8WM2HRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e39059-365a-4115-a60e-755380ac8565"
      },
      "source": [
        "print(train_loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[267.29035329818726, 66.03806138038635, 34.24101364612579, 16.44493079185486]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz23rcyLh_TQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d685f8c3-a543-4ee3-f8aa-f1b44b80899a"
      },
      "source": [
        "# Andreas' code he ask us to run on slack \n",
        "from prettytable import PrettyTable\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------+------------+\n",
            "|                      Modules                       | Parameters |\n",
            "+----------------------------------------------------+------------+\n",
            "|    encoder.layer.10.attention.self.query.weight    |   589824   |\n",
            "|     encoder.layer.10.attention.self.query.bias     |    768     |\n",
            "|     encoder.layer.10.attention.self.key.weight     |   589824   |\n",
            "|      encoder.layer.10.attention.self.key.bias      |    768     |\n",
            "|    encoder.layer.10.attention.self.value.weight    |   589824   |\n",
            "|     encoder.layer.10.attention.self.value.bias     |    768     |\n",
            "|   encoder.layer.10.attention.output.dense.weight   |   589824   |\n",
            "|    encoder.layer.10.attention.output.dense.bias    |    768     |\n",
            "| encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n",
            "|  encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n",
            "|     encoder.layer.10.intermediate.dense.weight     |  2359296   |\n",
            "|      encoder.layer.10.intermediate.dense.bias      |    3072    |\n",
            "|        encoder.layer.10.output.dense.weight        |  2359296   |\n",
            "|         encoder.layer.10.output.dense.bias         |    768     |\n",
            "|      encoder.layer.10.output.LayerNorm.weight      |    768     |\n",
            "|       encoder.layer.10.output.LayerNorm.bias       |    768     |\n",
            "|    encoder.layer.11.attention.self.query.weight    |   589824   |\n",
            "|     encoder.layer.11.attention.self.query.bias     |    768     |\n",
            "|     encoder.layer.11.attention.self.key.weight     |   589824   |\n",
            "|      encoder.layer.11.attention.self.key.bias      |    768     |\n",
            "|    encoder.layer.11.attention.self.value.weight    |   589824   |\n",
            "|     encoder.layer.11.attention.self.value.bias     |    768     |\n",
            "|   encoder.layer.11.attention.output.dense.weight   |   589824   |\n",
            "|    encoder.layer.11.attention.output.dense.bias    |    768     |\n",
            "| encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n",
            "|  encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n",
            "|     encoder.layer.11.intermediate.dense.weight     |  2359296   |\n",
            "|      encoder.layer.11.intermediate.dense.bias      |    3072    |\n",
            "|        encoder.layer.11.output.dense.weight        |  2359296   |\n",
            "|         encoder.layer.11.output.dense.bias         |    768     |\n",
            "|      encoder.layer.11.output.LayerNorm.weight      |    768     |\n",
            "|       encoder.layer.11.output.LayerNorm.bias       |    768     |\n",
            "+----------------------------------------------------+------------+\n",
            "Total Trainable Params: 14175744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14175744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CrjtoTY1pCv"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}