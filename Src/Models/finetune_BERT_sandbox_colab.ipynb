{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune_BERT_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRU4K5zWVemp"
      },
      "source": [
        "This is the SANDBOX version of finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6qtNFQyCIsv"
      },
      "source": [
        "# Start cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soayi6Ax2IvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8178857-8d09-432f-f9e1-cca1c657b9da"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhfaJA87lU-"
      },
      "source": [
        "# Loading requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBaXjuKD7ohz",
        "outputId": "f5a9d300-e2ae-4fee-971b-0ca1416715f8"
      },
      "source": [
        "! pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.11.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyBsg1w_7qyN",
        "outputId": "76d4e982-afd3-42d7-f175-9a6dcd7a0483"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROqy8ROq8zf5"
      },
      "source": [
        "# Import things to get data to work\n",
        "from datasets import load_from_disk\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vOZHVO25zRn"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6q90R05g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0812dc7b-89d1-43a5-f1c5-f53b9e9cb623"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvO9AFoF9KGo"
      },
      "source": [
        "sys.path.append(os.path.join('/content/drive/My Drive/deep_learning_project'))\n",
        "train_path = 'drive/My Drive/deep_learning_project/all_data/train_all'\n",
        "val_path = 'drive/My Drive/deep_learning_project/all_data/validation_all'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww9b_fsX5nXx"
      },
      "source": [
        "train_data = load_from_disk(train_path)\n",
        "validation_data = load_from_disk(val_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2EhY8a58yaq",
        "outputId": "5d990a7d-08db-4d95-82b2-77553f72a989"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'answer': 'york', 'paragraph': 'judi dench born in dorset and later moved to dublin where he was raised he met dench s mother while he was studying medicine at trinity college dublin dench attended the mount school a quaker independent secondary school in york and became a quaker her brothers one of whom was actor jeffery dench were born in tyldesley lancashire her niece emma dench is a roman historian and professor previously at birkbeck university of london and currently at harvard university career in britain dench has developed a reputation as one of the greatest actresses of the post war period primarily through her work in theatre which has been her forte throughout her career she has more than once been named number one in polls for britain s best actor early years', 'question': 'Where in England was Dame Judi Dench born?', 'question_id': 'tc_3'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4JOtDMX9tyq"
      },
      "source": [
        "# Preparing data for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI0jM5Xl9_kn"
      },
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel, AdamW"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm_gD863_UBR"
      },
      "source": [
        "def get_loss(sim):\n",
        "    nll = -(torch.diagonal(sim) - torch.logsumexp(sim, dim = 1))\n",
        "    return sum(nll)# return negative loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJOd_09093vQ"
      },
      "source": [
        "# Define data parameters\n",
        "batch_size = 100\n",
        "\n",
        "# Train\n",
        "n_sample_train = 1000 #ceil(len(train_data)*0.02) \n",
        "n_batches_train = ceil(n_sample_train/batch_size)\n",
        "# Validation\n",
        "n_sample_validation = 200 #ceil(len(validation_data)*0.05)\n",
        "n_batches_validation = ceil(n_sample_validation/batch_size)\n",
        "\n",
        "\n",
        "# Define model parameters\n",
        "lr = 5e-5\n",
        "n_epochs = 4\n",
        "\n",
        "# Define printing parameters\n",
        "n_batch_print = 5 # Prints every (n_batch_print) during training"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYfy9sQoKS7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3ee8f2-6e74-4b3a-b7ce-abd6254b7d84"
      },
      "source": [
        "print(f\"Validation Samples: {n_sample_validation}\")\n",
        "print(f\"Training Samples: {n_sample_train}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Samples: 200\n",
            "Training Samples: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAJeVShU-JLO",
        "outputId": "04d84b3f-1781-436a-f271-9fbaf8051f05"
      },
      "source": [
        "# NB CHANGE THIS CELL WHEN THE DATA IS READY###############\n",
        "# Subset data\n",
        "train_data = train_data.select(range(n_sample_train))\n",
        "validation_data = validation_data.select(range(n_sample_validation))\n",
        "\n",
        "# Tokenize data\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', padding = True)\n",
        "train_data = train_data.map(lambda example: {\n",
        "    'Q_input_ids': tokenizer(example['question'], padding = 'max_length')['input_ids'],\n",
        "    'Q_attention_mask': tokenizer(example['question'], padding = 'max_length')['attention_mask'],\n",
        "    'Q_token_type_ids': tokenizer(example['question'], padding = 'max_length')['token_type_ids'],\n",
        "    'P_input_ids': tokenizer(example['paragraph'], padding = 'max_length')['input_ids'],\n",
        "    'P_attention_mask': tokenizer(example['paragraph'], padding = 'max_length')['attention_mask'],\n",
        "    'P_token_type_ids': tokenizer(example['paragraph'], padding = 'max_length')['token_type_ids']},\n",
        "    batched = True, batch_size= batch_size)\n",
        "\n",
        "validation_data = validation_data.map(lambda example: {\n",
        "    'Q_input_ids': tokenizer(example['question'], padding = 'max_length')['input_ids'],\n",
        "    'Q_attention_mask': tokenizer(example['question'], padding = 'max_length')['attention_mask'],\n",
        "    'Q_token_type_ids': tokenizer(example['question'], padding = 'max_length')['token_type_ids'],\n",
        "    'P_input_ids': tokenizer(example['paragraph'], padding = 'max_length')['input_ids'],\n",
        "    'P_attention_mask': tokenizer(example['paragraph'], padding = 'max_length')['attention_mask'],\n",
        "    'P_token_type_ids': tokenizer(example['paragraph'], padding = 'max_length')['token_type_ids']},\n",
        "    batched = True, batch_size= batch_size)\n",
        "\n",
        "#%% Change to pytorch format. \n",
        "train_data.set_format(type = 'torch', \n",
        "                        columns = ['Q_input_ids', 'Q_attention_mask', 'Q_token_type_ids',\n",
        "                                   'P_input_ids', 'P_attention_mask', 'P_token_type_ids'])\n",
        "\n",
        "validation_data.set_format(type = 'torch', \n",
        "                        columns = ['Q_input_ids', 'Q_attention_mask', 'Q_token_type_ids',\n",
        "                                   'P_input_ids', 'P_attention_mask', 'P_token_type_ids'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at drive/My Drive/deep_learning_project/all_data/train_all/cache-2e0fa9fa098203ed.arrow\n",
            "Loading cached processed dataset at drive/My Drive/deep_learning_project/all_data/validation_all/cache-738eea6eae32532b.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlh6z4VKLtN"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmRsdg1d-xrw"
      },
      "source": [
        "# Get pretrained model\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Freezing all layers except the last ones\n",
        "layers_to_opt = [\"encoder.layer.11\" in name[0] for name in model.named_parameters()]\n",
        "params = [name[0] for name in model.named_parameters()]\n",
        "param_to_be_optimized = [name for (layer, name) in zip(layers_to_opt, params) if layer]\n",
        "for name, param in model.named_parameters():\n",
        "  if not name in param_to_be_optimized:\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Move model to cuda to train there\n",
        "model.to(device)\n",
        "\n",
        "optim = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr = lr) # filter object works as a generator "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRAU6y9JMa__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518c5cc1-0e24-428d-dbc7-64442ef8e229"
      },
      "source": [
        "# Print the weights that are being updated\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder.layer.11.attention.self.query.weight\n",
            "encoder.layer.11.attention.self.query.bias\n",
            "encoder.layer.11.attention.self.key.weight\n",
            "encoder.layer.11.attention.self.key.bias\n",
            "encoder.layer.11.attention.self.value.weight\n",
            "encoder.layer.11.attention.self.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.weight\n",
            "encoder.layer.11.attention.output.LayerNorm.bias\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.weight\n",
            "encoder.layer.11.output.LayerNorm.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "fPZogvfK9vF2",
        "outputId": "2d53dbe3-aec9-4614-996a-7f0ee794716a"
      },
      "source": [
        "# The big loop :D \n",
        "epoch_train_loss = [None]*n_batches_train\n",
        "epoch_validation_loss = [None]*n_batches_validation\n",
        "train_loss = [None]*n_epochs\n",
        "validation_loss = [None]*n_epochs\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    print(f'### EPOCH: {epoch+1}/{n_epochs} ###')\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    trainloader = iter(trainloader)\n",
        "    validationloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size)\n",
        "    validationloader = iter(validationloader)\n",
        "    \n",
        "    # TRAINING MODEL\n",
        "    model.train()\n",
        "    for i, batch in enumerate(trainloader):\n",
        "        if i % n_batch_print == 0:\n",
        "          print(f'batch {i+1}/{len(trainloader)}')\n",
        "        \n",
        "        model.zero_grad()\n",
        "\n",
        "        # Make forward pass for paragraphs\n",
        "        input_ids = batch['P_input_ids'].to(device)\n",
        "        attention_mask = batch['P_attention_mask'].to(device)\n",
        "        token_type_ids = batch['P_token_type_ids'].to(device)\n",
        "        P_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)[0][:, 0, :]\n",
        "        \n",
        "        # Make forward pass for questions\n",
        "        input_ids = batch['Q_input_ids'].to(device)\n",
        "        attention_mask = batch['Q_attention_mask'].to(device)\n",
        "        token_type_ids = batch['Q_token_type_ids'].to(device)\n",
        "        Q_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)[0][:, 0, :]\n",
        "    \n",
        "        # Calculate similarity matrix\n",
        "        sim_matrix = torch.matmul(Q_encoded_layers, P_encoded_layers.T)\n",
        "        \n",
        "        # Get loss\n",
        "        loss = get_loss(sim_matrix)\n",
        "        loss.requires_grad = True\n",
        "\n",
        "        # Update weights\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        # Save loss\n",
        "        epoch_train_loss[i] = loss.item()\n",
        "\n",
        "    # VALIDATING MODEL\n",
        "    #model.eval()\n",
        "    for i, batch in enumerate(validationloader):\n",
        "        \n",
        "        # (get extra observation in training set)\n",
        "\n",
        "        # Make forward pass for paragraphs\n",
        "        input_ids = batch['P_input_ids'].to(device)\n",
        "        attention_mask = batch['P_attention_mask'].to(device)\n",
        "        token_type_ids = batch['P_token_type_ids'].to(device)\n",
        "        P_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)[0][:, 0, :]\n",
        "        \n",
        "        # Make forward pass for questions\n",
        "        input_ids = batch['Q_input_ids'].to(device)\n",
        "        attention_mask = batch['Q_attention_mask'].to(device)\n",
        "        token_type_ids = batch['Q_token_type_ids'].to(device)\n",
        "        Q_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)[0][:, 0, :]\n",
        "      \n",
        "        # Calculate similarity matrix\n",
        "        sim_matrix = torch.matmul(Q_encoded_layers, P_encoded_layers.T)\n",
        "        \n",
        "        # Get loss\n",
        "        loss = get_loss(sim_matrix)\n",
        "        epoch_validation_loss[i] = loss.item()\n",
        "        \n",
        "    \n",
        "    train_loss[epoch] = sum(epoch_train_loss)/len(epoch_train_loss)\n",
        "    validation_loss[epoch] = sum(epoch_validation_loss)/len(epoch_validation_loss)\n",
        "    \n",
        "    print(f'train loss: {train_loss[epoch]:.2f}')\n",
        "    print(f'validation loss: {validation_loss[epoch]:.2f}')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### EPOCH: 1/4 ###\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py:850: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.tensor(x, **format_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2c2680f3f8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         Q_encoded_layers = model(input_ids=input_ids, \n\u001b[1;32m     38\u001b[0m                           \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                           token_type_ids=token_type_ids, output_hidden_states = True)[0][:, 0, :]\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Calculate similarity matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 )\n\u001b[1;32m    490\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    981\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 14.73 GiB total capacity; 11.62 GiB already allocated; 903.88 MiB free; 12.80 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hH7-eSbjpHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c60596f-30c2-48f1-e704-beb87b4b777a"
      },
      "source": [
        "#Q_encoded_layers.shape\n",
        "#batch.keys()\n",
        "#batch[\"Q_input_ids\"].shape\n",
        "#tmp = model(input_ids=input_ids, \n",
        "#                          attention_mask=attention_mask, \n",
        "#                          token_type_ids=token_type_ids)\n",
        "\n",
        "#print(tmp.pooler_output.size())\n",
        "#print(Q_encoded_layers.shape)\n",
        "#tmp.last_hidden_state.size()\n",
        "\n",
        "tmp = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids, output_hidden_states = True)\n",
        "\n",
        "hej = torch.cat(tuple([tmp.hidden_states[i] for i in [-4, -3, -2, -1]]), dim=-1)\n",
        "hej = hej[:, 0, :]\n",
        "hej = self.dropout(hej)\n",
        "hej.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([26, 512, 3072])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnB-hrrIOe-S"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3i1oLjBWL9E"
      },
      "source": [
        "print(validation_loss)\n",
        "print(train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM095XYxWEpe"
      },
      "source": [
        "#%% Saving model\n",
        "model_path = 'drive/My Drive/BERT_Model/8_percent/'\n",
        "model.save_pretrained(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOaGE4RAaaA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "80e3af0b-aaa6-4269-d76b-08b0420557a9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(range(1, n_epochs+1), train_loss, label = 'Train loss')\n",
        "plt.plot(range(1, n_epochs+1), validation_loss, label = 'Validation loss')\n",
        "plt.title('Finetuning BERT Base Model')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "#fig.savefig(\"drive/My Drive/deep_learning_project/figures/BERTbaseFinetuning_pooled_output.pdf\", bbox_inches='tight')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcJgm4bKCQ9M"
      },
      "source": [
        "validation_loss\n",
        "train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt6-DU072GYx"
      },
      "source": [
        "print(validation_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC4ui8WM2HRZ"
      },
      "source": [
        "print(train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz23rcyLh_TQ"
      },
      "source": [
        "# Andreas' code he ask us to run on slack \n",
        "from prettytable import PrettyTable\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CrjtoTY1pCv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}