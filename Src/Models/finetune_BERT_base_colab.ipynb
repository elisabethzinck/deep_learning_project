{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune_BERT_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fb331277b9d4fdfa073abc7895fabad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3032a149b85e49609eb13fdc49845ac1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_783c15c98ef842daa9b372c1caecacc5",
              "IPY_MODEL_d1311514334e430f990c26cca4fb32d7"
            ]
          }
        },
        "3032a149b85e49609eb13fdc49845ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "783c15c98ef842daa9b372c1caecacc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ece4cb0768b34896adc671dc1d49656d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 116,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 116,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_834b7ac57e5748db93381b60bdc3e8bd"
          }
        },
        "d1311514334e430f990c26cca4fb32d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8b3c395cee746bf9eccc2c05dccaec5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 116/116 [50:59&lt;00:00, 26.38s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb5f4d569dfc48eda73609c6fac4ae6f"
          }
        },
        "ece4cb0768b34896adc671dc1d49656d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "834b7ac57e5748db93381b60bdc3e8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8b3c395cee746bf9eccc2c05dccaec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb5f4d569dfc48eda73609c6fac4ae6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46eee6b615b940749c169913b7a5950e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a60ac37f2bd4fb09db2833becad734a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a36594c0bf2446eba23e001d2b11756b",
              "IPY_MODEL_6e58f05739be49af9f184523a556f022"
            ]
          }
        },
        "9a60ac37f2bd4fb09db2833becad734a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a36594c0bf2446eba23e001d2b11756b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9f51c69c0df4b29b25343e9cdf263be",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acc165a40d6b4de992ff7fd2cbe0288f"
          }
        },
        "6e58f05739be49af9f184523a556f022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98ffcad2a98d44d68e7c302b513a8bb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [50:40&lt;00:00, 145kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9531000bb24e4d5db577d15186b8ed02"
          }
        },
        "f9f51c69c0df4b29b25343e9cdf263be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acc165a40d6b4de992ff7fd2cbe0288f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98ffcad2a98d44d68e7c302b513a8bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9531000bb24e4d5db577d15186b8ed02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6qtNFQyCIsv"
      },
      "source": [
        "# Start cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soayi6Ax2IvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80173355-beaa-4bb8-eff2-96a13e8e9a24"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhfaJA87lU-"
      },
      "source": [
        "# Loading requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBaXjuKD7ohz",
        "outputId": "6254cd9b-df33-407f-ed6f-f9e6ac4c3c3a"
      },
      "source": [
        "! pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 12.7MB/s \n",
            "\u001b[?25hCollecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 177kB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: pyarrow, xxhash, datasets\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.1.3 pyarrow-2.0.0 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyBsg1w_7qyN",
        "outputId": "87aea34d-c0f0-48ff-cefc-6ac0cae76c41"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 15.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 12.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 12.0MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 12.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=572e3e52c76026af0ad2a491fe00084fe994f40b1cec9aa6e27cc38f2d71237c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROqy8ROq8zf5"
      },
      "source": [
        "# Import things to get data to work\n",
        "from datasets import load_from_disk\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vOZHVO25zRn"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6q90R05g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198ac839-fe01-4e80-c6e2-89f497786ebd"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvO9AFoF9KGo"
      },
      "source": [
        "sys.path.append(os.path.join('/content/drive/My Drive/deep_learning_project'))\n",
        "train_path = 'drive/My Drive/deep_learning_project/all_data/train_all'\n",
        "val_path = 'drive/My Drive/deep_learning_project/all_data/validation_all'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww9b_fsX5nXx"
      },
      "source": [
        "train_data = load_from_disk(train_path)\n",
        "validation_data = load_from_disk(val_path)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2EhY8a58yaq",
        "outputId": "c15ea5df-5e2c-445d-95fe-ff420fe93bfb"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'answer': 'york', 'paragraph': 'judi dench born in dorset and later moved to dublin where he was raised he met dench s mother while he was studying medicine at trinity college dublin dench attended the mount school a quaker independent secondary school in york and became a quaker her brothers one of whom was actor jeffery dench were born in tyldesley lancashire her niece emma dench is a roman historian and professor previously at birkbeck university of london and currently at harvard university career in britain dench has developed a reputation as one of the greatest actresses of the post war period primarily through her work in theatre which has been her forte throughout her career she has more than once been named number one in polls for britain s best actor early years', 'question': 'Where in England was Dame Judi Dench born?', 'question_id': 'tc_3'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4JOtDMX9tyq"
      },
      "source": [
        "# Preparing data for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI0jM5Xl9_kn"
      },
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel, AdamW, BertForSequenceClassification"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm_gD863_UBR"
      },
      "source": [
        "def get_loss(sim):\n",
        "    nll = -(torch.diagonal(sim) - torch.logsumexp(sim, dim = 1))\n",
        "    return sum(nll)# return negative loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJOd_09093vQ"
      },
      "source": [
        "# Define data parameters\n",
        "batch_size = 100\n",
        "\n",
        "# Train\n",
        "n_sample_train = ceil(len(train_data)*0.70) \n",
        "n_batches_train = ceil(n_sample_train/batch_size)\n",
        "# Validation\n",
        "n_sample_validation = ceil(len(validation_data)*0.70)\n",
        "n_batches_validation = ceil(n_sample_validation/batch_size)\n",
        "\n",
        "\n",
        "# Define model parameters\n",
        "lr = 5e-5\n",
        "n_epochs = 4\n",
        "\n",
        "# Define printing parameters\n",
        "n_batch_print = 50 # Prints every (n_batch_print) during training"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYfy9sQoKS7X",
        "outputId": "397969d2-7ecc-4f46-a1e3-86cc0365fce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(n_sample_validation)\n",
        "print(n_sample_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11553\n",
            "87579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "8fb331277b9d4fdfa073abc7895fabad",
            "3032a149b85e49609eb13fdc49845ac1",
            "783c15c98ef842daa9b372c1caecacc5",
            "d1311514334e430f990c26cca4fb32d7",
            "ece4cb0768b34896adc671dc1d49656d",
            "834b7ac57e5748db93381b60bdc3e8bd",
            "a8b3c395cee746bf9eccc2c05dccaec5",
            "fb5f4d569dfc48eda73609c6fac4ae6f"
          ]
        },
        "id": "iAJeVShU-JLO",
        "outputId": "b099fb3d-5fe0-4bba-933e-a6098161c3ad"
      },
      "source": [
        "# NB CHANGE THIS CELL WHEN THE DATA IS READY###############\n",
        "# Subset data\n",
        "train_data = train_data.select(range(n_sample_train))\n",
        "validation_data = validation_data.select(range(n_sample_validation))\n",
        "\n",
        "# Tokenize data\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', padding = True)\n",
        "train_data = train_data.map(lambda example: {\n",
        "    'Q_input_ids': tokenizer(example['question'], padding = 'max_length')['input_ids'],\n",
        "    'Q_attention_mask': tokenizer(example['question'], padding = 'max_length')['attention_mask'],\n",
        "    'Q_token_type_ids': tokenizer(example['question'], padding = 'max_length')['token_type_ids'],\n",
        "    'P_input_ids': tokenizer(example['paragraph'], padding = 'max_length')['input_ids'],\n",
        "    'P_attention_mask': tokenizer(example['paragraph'], padding = 'max_length')['attention_mask'],\n",
        "    'P_token_type_ids': tokenizer(example['paragraph'], padding = 'max_length')['token_type_ids']},\n",
        "    batched = True, batch_size= batch_size)\n",
        "\n",
        "validation_data = validation_data.map(lambda example: {\n",
        "    'Q_input_ids': tokenizer(example['question'], padding = 'max_length')['input_ids'],\n",
        "    'Q_attention_mask': tokenizer(example['question'], padding = 'max_length')['attention_mask'],\n",
        "    'Q_token_type_ids': tokenizer(example['question'], padding = 'max_length')['token_type_ids'],\n",
        "    'P_input_ids': tokenizer(example['paragraph'], padding = 'max_length')['input_ids'],\n",
        "    'P_attention_mask': tokenizer(example['paragraph'], padding = 'max_length')['attention_mask'],\n",
        "    'P_token_type_ids': tokenizer(example['paragraph'], padding = 'max_length')['token_type_ids']},\n",
        "    batched = True, batch_size= batch_size)\n",
        "\n",
        "#%% Change to pytorch format. \n",
        "train_data.set_format(type = 'torch', \n",
        "                        columns = ['Q_input_ids', 'Q_attention_mask', 'Q_token_type_ids',\n",
        "                                   'P_input_ids', 'P_attention_mask', 'P_token_type_ids'])\n",
        "\n",
        "validation_data.set_format(type = 'torch', \n",
        "                        columns = ['Q_input_ids', 'Q_attention_mask', 'Q_token_type_ids',\n",
        "                                   'P_input_ids', 'P_attention_mask', 'P_token_type_ids'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at drive/My Drive/deep_learning_project/all_data/train_all/cache-17b2039bdcf4806b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fb331277b9d4fdfa073abc7895fabad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=116.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlh6z4VKLtN"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmRsdg1d-xrw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "46eee6b615b940749c169913b7a5950e",
            "9a60ac37f2bd4fb09db2833becad734a",
            "a36594c0bf2446eba23e001d2b11756b",
            "6e58f05739be49af9f184523a556f022",
            "f9f51c69c0df4b29b25343e9cdf263be",
            "acc165a40d6b4de992ff7fd2cbe0288f",
            "98ffcad2a98d44d68e7c302b513a8bb4",
            "9531000bb24e4d5db577d15186b8ed02"
          ]
        },
        "outputId": "674cb7d7-b49a-41ec-d80f-738f9fbb3aaf"
      },
      "source": [
        "# Get pretrained model\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Freezing all parameters except the last ones (I think - double check this)\n",
        "param_to_be_optimized = ['pooler.dense.weight', 'pooler.dense.bias']\n",
        "for name, param in model.named_parameters():\n",
        "  #print(name)\n",
        "  if not name in param_to_be_optimized:\n",
        "    param.requires_grad = False\n",
        "\n",
        "# --------- From Hugging Face ---------------\n",
        "#for name, param in model.base_model.named_parameters():\n",
        "#  param.requires_grad = False\n",
        "  #if(param.requires_grad): \n",
        "   # print(name)\n",
        "#for name, param in model.named_parameters():\n",
        "#  if(param.requires_grad): \n",
        "#    print(name)\n",
        "# -----------------------------------------\n",
        "\n",
        "# Checking we have frozen the right layers \n",
        "for name, param in model.named_parameters():\n",
        "  if(param.requires_grad): \n",
        "    print(name)\n",
        "\n",
        "# Move model to cuda to train there\n",
        "model.to(device)\n",
        "\n",
        "optim = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr = lr) # filter object works as a generator "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46eee6b615b940749c169913b7a5950e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "pooler.dense.weight\n",
            "pooler.dense.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfYwHB6I24Lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28eb35e-861f-438d-d587-4c19f2982f5b"
      },
      "source": [
        "# ADAM gets the correct bias and weigths\n",
        "optim.param_groups[0]['params'][1].size()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuKw1nnp5m1X"
      },
      "source": [
        "# Printing layers in model to compare \n",
        "#model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRAU6y9JMa__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75756c4c-1023-450a-a096-3dd269dbd4fc"
      },
      "source": [
        "# Print the weights that are being updated\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pooler.dense.weight\n",
            "pooler.dense.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "fPZogvfK9vF2",
        "outputId": "98bf1a50-9604-4246-8635-4bd3b8f3730b"
      },
      "source": [
        "# The big loop :D \n",
        "epoch_train_loss = [None]*n_batches_train\n",
        "epoch_validation_loss = [None]*n_batches_validation\n",
        "train_loss = [None]*n_epochs\n",
        "validation_loss = [None]*n_epochs\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    print(f'### EPOCH: {epoch+1}/{n_epochs} ###')\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    trainloader = iter(trainloader)\n",
        "    validationloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size)\n",
        "    validationloader = iter(validationloader)\n",
        "    \n",
        "    # TRAINING MODEL\n",
        "    model.train()\n",
        "    for i, batch in enumerate(trainloader):\n",
        "        if i % n_batch_print == 0:\n",
        "          print(f'batch {i+1}/{len(trainloader)}')\n",
        "        \n",
        "        model.zero_grad()\n",
        "\n",
        "        # (get extra observation in training set)\n",
        "        # Make forward pass for paragraphs\n",
        "        input_ids = batch['P_input_ids'].to(device)\n",
        "        attention_mask = batch['P_attention_mask'].to(device)\n",
        "        token_type_ids = batch['P_token_type_ids'].to(device)\n",
        "        P_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids)[0][:, 0, :]\n",
        "\n",
        "        # Make forward pass for questions\n",
        "        input_ids = batch['Q_input_ids'].to(device)\n",
        "        attention_mask = batch['Q_attention_mask'].to(device)\n",
        "        token_type_ids = batch['Q_token_type_ids'].to(device)\n",
        "        Q_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids)[0][:, 0, :]\n",
        "    \n",
        "    \n",
        "        # Calculate similarity matrix\n",
        "        sim_matrix = torch.matmul(Q_encoded_layers, P_encoded_layers.T)\n",
        "        \n",
        "        # Get loss\n",
        "        loss = get_loss(sim_matrix)\n",
        "        loss.requires_grad = True\n",
        "\n",
        "        # Update weights\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        # Save loss\n",
        "        epoch_train_loss[i] = loss.item()\n",
        "\n",
        "    # VALIDATING MODEL\n",
        "    #model.eval()\n",
        "    for i, batch in enumerate(validationloader):\n",
        "        \n",
        "        # (get extra observation in training set)\n",
        "\n",
        "        # Make forward pass for paragraphs\n",
        "        input_ids = batch['P_input_ids'].to(device)\n",
        "        attention_mask = batch['P_attention_mask'].to(device)\n",
        "        token_type_ids = batch['P_token_type_ids'].to(device)\n",
        "        P_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids)[0][:, 0, :]\n",
        "\n",
        "        # Make forward pass for questions\n",
        "        input_ids = batch['Q_input_ids'].to(device)\n",
        "        attention_mask = batch['Q_attention_mask'].to(device)\n",
        "        token_type_ids = batch['Q_token_type_ids'].to(device)\n",
        "        Q_encoded_layers = model(input_ids=input_ids, \n",
        "                          attention_mask=attention_mask, \n",
        "                          token_type_ids=token_type_ids)[0][:, 0, :]\n",
        "    \n",
        "    \n",
        "        # Calculate similarity matrix\n",
        "        sim_matrix = torch.matmul(Q_encoded_layers, P_encoded_layers.T)\n",
        "        \n",
        "        # Get loss\n",
        "        loss = get_loss(sim_matrix)\n",
        "        epoch_validation_loss[i] = loss.item()\n",
        "        \n",
        "    \n",
        "    train_loss[epoch] = sum(epoch_train_loss)/len(epoch_train_loss)\n",
        "    validation_loss[epoch] = sum(epoch_validation_loss)/len(epoch_validation_loss)\n",
        "    \n",
        "    print(f'train loss: {train_loss[epoch]:.2f}')\n",
        "    print(f'validation loss: {validation_loss[epoch]:.2f}')\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### EPOCH: 1/4 ###\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py:850: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.tensor(x, **format_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch 1/876\n",
            "batch 51/876\n",
            "batch 101/876\n",
            "batch 151/876\n",
            "batch 201/876\n",
            "batch 251/876\n",
            "batch 301/876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-084cca1b9819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Save loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# VALIDATING MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnB-hrrIOe-S"
      },
      "source": [
        "#model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3i1oLjBWL9E"
      },
      "source": [
        "print(validation_loss)\n",
        "print(training_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM095XYxWEpe"
      },
      "source": [
        "#%% Saving model\n",
        "model_path = 'drive/My Drive/deep_learning_project/model_bert_base_only_outer_layers/'\n",
        "model.save_pretrained(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOaGE4RAaaA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(range(1, n_epochs+1), train_loss, label = 'Train loss')\n",
        "plt.plot(range(1, n_epochs+1), validation_loss, label = 'Validation loss')\n",
        "plt.title('Finetuning BERT Base Model')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "fig.savefig(\"drive/My Drive/deep_learning_project/figures/BERTbaseFinetuning.pdf\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcJgm4bKCQ9M"
      },
      "source": [
        "validation_loss\n",
        "train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt6-DU072GYx"
      },
      "source": [
        "print(validation_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC4ui8WM2HRZ"
      },
      "source": [
        "print(train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}